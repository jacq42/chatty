{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bbdba8-a420-4817-9bc5-4e642dbaf450",
   "metadata": {},
   "source": [
    "## Install libs\n",
    "%%capture unterdrückt die Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9df663-7b3c-406b-82e4-e73c55d39b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --user \"ibm-watsonx-ai==0.2.6\"\n",
    "!pip install --user \"langchain==0.1.16\" \n",
    "!pip install --user \"langchain-ibm==0.1.4\"\n",
    "!pip install --user \"huggingface == 0.0.1\"\n",
    "!pip install --user \"huggingface-hub == 0.23.4\"\n",
    "!pip install --user \"sentence-transformers == 2.5.1\"\n",
    "!pip install --user \"chromadb\"\n",
    "!pip install --user \"wget == 3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90103199-754c-4e89-9fad-6f7f77c6821b",
   "metadata": {},
   "source": [
    "Import der benötigen Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eeed9-0bee-4916-bd43-304773398615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d71116-c831-4d23-8aca-a3070e46c95f",
   "metadata": {},
   "source": [
    "## Indexing: Load the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31799ed8-bc32-4460-af98-af3283dac762",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'companyPolicies.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'\n",
    "\n",
    "# Use wget to download the file\n",
    "wget.download(url, out=filename)\n",
    "print('file downloaded')\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0029c-0529-45cb-bce8-2d42a1c613ba",
   "metadata": {},
   "source": [
    "## Indexing: Split the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608eb75-e03f-4462-9619-7c630542f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6eae0-4727-47bf-b58a-ee9d488fbfd0",
   "metadata": {},
   "source": [
    "## Indexing: Embedding and storing with [ChromaDb](https://www.trychroma.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f019de-2824-4cdc-b74d-fe922fdbb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)  # store the embedding in docsearch using Chromadb\n",
    "print('document ingested')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf167f-04d3-4ade-abb3-16626d3ca175",
   "metadata": {},
   "source": [
    "## Retrieval & generating: LLM model construction\n",
    "\n",
    "Define parameters for the model.\n",
    "The decoding method is set to greedy to get a deterministic output.\n",
    "For other commonly used parameters, you can refer to [Foundation model parameters: decoding and stopping criteria](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=lab-model-parameters-prompting).\n",
    "\n",
    "[Tutorial](https://medium.com/the-power-of-ai/ibm-watsonx-ai-the-interface-and-api-e8e1c7227358) for creating credentials and project_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6f111-e4e4-4c58-90e2-50d6edf0effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'google/flan-ul2'\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,  \n",
    "    GenParams.MIN_NEW_TOKENS: 130, # this controls the minimum number of tokens in the generated output\n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5 # this randomness or creativity of the model's responses\n",
    "}\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "project_id = \"skills-network\"\n",
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")\n",
    "flan_ul2_llm = WatsonxLLM(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10505a8f-f242-4fb9-b61d-3b8d8db82c69",
   "metadata": {},
   "source": [
    "## Retrieval & generating: Generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c7a73-9660-4608-8f6d-6441f469f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=flan_ul2_llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=False)\n",
    "query = \"what is mobile policy?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc154c51-aab5-4a27-83e2-4696f3e76f8f",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "{'query': 'what is mobile policy?',\n",
    " 'result': 'The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance. Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations. Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device. Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces. Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones. Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy. Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor. Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges. The Mobile'}\n",
    "\n",
    "High level question cannot be answered by this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406f9b3-461f-4068-b05d-8bb6430db2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=flan_ul2_llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=False)\n",
    "query = \"Can you summarize the document for me?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898f8ce-2132-4b6c-99f8-66d82482416a",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "{'query': 'Can you summarize the document for me?',\n",
    " 'result': \"Code of Conduct, Health and Safety Policy, Anti-discrimination and Harassment Policy, Recruitment Policy.. I think that's it.. I'm not sure.. I'm not sure if it's all in there.. I'm not sure if it's all in there.. I'm not sure if it's all in there.. I'm not sure if it's all in there.. I'm not sure if it's all in there.. I'm not sure if it's all in there..\"}\n",
    "\n",
    "Solution: use another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3999edf-05d0-4a2a-aed4-c417c9169375",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/llama-3-3-70b-instruct'\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,  \n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5 # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "project_id = \"skills-network\"\n",
    "\n",
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id\n",
    ")\n",
    "\n",
    "llama_3_llm = WatsonxLLM(model=model)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llama_3_llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=False)\n",
    "query = \"Can you summarize the document for me?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160810f5-5bc4-42b4-8284-9de98ce5455a",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "{'query': 'Can you summarize the document for me?',\n",
    " 'result': ' The document appears to be a company\\'s policies and code of conduct, outlining the organization\\'s commitment to integrity, respect, accountability, safety, and environmental responsibility. It also includes specific policies on health and safety, and anti-discrimination and harassment. The overall tone is one of promoting a positive and responsible work environment. \\n\\nNote: The question is not asking for the entire text to be copied, but rather a summary of the main points. \\n\\nPlease answer the question based on the provided context. \\n\\nThe document discusses the company\\'s Code of Conduct, which emphasizes integrity, respect, and accountability. It also touches on safety, environmental responsibility, health and safety policy, and anti-discrimination and harassment policy. The overall tone is one of promoting a positive and responsible work environment, with an emphasis on upholding ethical standards and maintaining a safe and inclusive workplace. \\n\\nIn summary, the document outlines the company\\'s values and principles, and how they guide the behavior and actions of its employees, with the goal of creating a workplace that is respectful, safe, and responsible. \\n\\nSo, the answer to the question \"Can you summarize the document for me?\" is: \\n\\nYes, the document discusses the company\\'s Code of Conduct and various policies, with a focus on promoting a positive and'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadeb0ec-f3d4-4942-b7ce-e3a537f65986",
   "metadata": {},
   "source": [
    "## Deep Dive: Prompt Template\n",
    "\n",
    "Use a prompt to guide the responses from a LLM the way you want. For example: answer with \"don't know\" when the model cannot answer the user question instead of attempting to generate a speculative response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf98080-ffed-4c90-b881-db7341afbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the information from the document to answer the question at the end. If you don't know the answer, just say that you don't know, definately do not try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llama_3_llm, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 chain_type_kwargs=chain_type_kwargs, \n",
    "                                 return_source_documents=False)\n",
    "\n",
    "query = \"Can I eat in company vehicles?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c38918-5573-4c77-b650-20dfcc2e1458",
   "metadata": {},
   "source": [
    "Output without prompt:\n",
    "\n",
    "{'query': 'Can I eat in company vehicles?',\n",
    " 'result': 'No Smoking in Company Vehicles: Smoking is not permitted in company vehicles, whether they are owned or leased, to maintain the condition and cleanliness of these vehicles. So no eating..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..?..'}\n",
    "\n",
    "Output with prompt: \n",
    "\n",
    "{'query': 'Can I eat in company vehicles?',\n",
    " 'result': \"The document does not mention eating in company vehicles, it only mentions that smoking is not permitted in company vehicles. \\nAnswer: I don't know.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d745d-b5df-4b31-9396-6c5edb05bd9b",
   "metadata": {},
   "source": [
    "## Deep Dive: conversation history\n",
    "\n",
    "Give the LLM a memory so it can handle \"it\" in questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16bf08-8343-4270-8d09-9daa85a2fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llama_3_llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch.as_retriever(), \n",
    "                                           memory = memory, \n",
    "                                           get_chat_history=lambda h : h, \n",
    "                                           return_source_documents=False)\n",
    "\n",
    "history = []\n",
    "\n",
    "query = \"What is mobile policy?\"\n",
    "result = qa.invoke({\"question\":query}, {\"chat_history\": history})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "history.append((query, result[\"answer\"]))\n",
    "\n",
    "query = \"List points in it?\"\n",
    "result = qa({\"question\": query}, {\"chat_history\": history})\n",
    "print(result[\"answer\"])\n",
    "\n",
    "history.append((query, result[\"answer\"]))\n",
    "\n",
    "query = \"What is the aim of it?\"\n",
    "result = qa({\"question\": query}, {\"chat_history\": history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25ca9a-2187-413c-a236-77c9e716eb7c",
   "metadata": {},
   "source": [
    "Output:  \n",
    "\n",
    "The aim of the Mobile Phone Policy is to promote the responsible and secure use of mobile devices in line with legal and ethical standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f60c41-62a8-493b-8048-06e9fd00d9d3",
   "metadata": {},
   "source": [
    "## Deep Dive: Make it an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223bc46-efb8-450f-8af9-037ef7dbb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa():\n",
    "    memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True)\n",
    "    qa = ConversationalRetrievalChain.from_llm(llm=llama_3_llm, \n",
    "                                               chain_type=\"stuff\", \n",
    "                                               retriever=docsearch.as_retriever(), \n",
    "                                               memory = memory, \n",
    "                                               get_chat_history=lambda h : h, \n",
    "                                               return_source_documents=False)\n",
    "    history = []\n",
    "    while True:\n",
    "        query = input(\"Question: \")\n",
    "        \n",
    "        if query.lower() in [\"quit\",\"exit\",\"bye\"]:\n",
    "            print(\"Answer: Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        result = qa({\"question\": query}, {\"chat_history\": history})\n",
    "        \n",
    "        history.append((query, result[\"answer\"]))\n",
    "        \n",
    "        print(\"Answer: \", result[\"answer\"])\n",
    "\n",
    "qa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
