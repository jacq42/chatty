{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fac08a-4c3b-4bdc-8572-18f404bce41a",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Required libs:\n",
    "* langchain: Building applications with LLMs through composability.\n",
    "* ibm-watsonx-ai: ibm-watsonx-ai is a library that allows to work with watsonx.ai service on IBM Cloud and IBM Cloud for Data. Train, test, and deploy your models as APIs for application development and share with colleagues using this python library.\n",
    "* langchain-ibm: This package provides the integration between LangChain and IBM watsonx.ai through the ibm-watsonx-ai SDK.\n",
    "* unstructured: A library that prepares raw documents for downstream ML tasks.\n",
    "* ibm-watson-machine-learning: A library that allows to work with Watson Machine Learning service on IBM Cloud and IBM Cloud for Data. Train, test, and deploy your models as APIs for application development and share with colleagues using this python library.\n",
    "\n",
    "Install required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b82460-d738-43d0-abaa-8d1588c6f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain==0.2.6 | tail -n 1\n",
    "%pip install langchain_chroma==0.1.2 | tail -n 1\n",
    "%pip install langchain-community==0.2.6 | tail -n 1\n",
    "%pip install ibm-watsonx-ai==1.0.10 | tail -n 1\n",
    "%pip install langchain_ibm==0.1.11 | tail -n 1\n",
    "%pip install unstructured==0.15.0 | tail -n 1\n",
    "%pip install ibm-watson-machine-learning==1.0.360 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e524c2c-cfa3-4879-9912-09b1deb00940",
   "metadata": {},
   "source": [
    "Import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090c395-c49f-437c-88d5-5d9d9b448838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import os\n",
    "\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
    "\n",
    "from langchain_ibm import WatsonxEmbeddings, WatsonxLLM\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe852e-214b-4645-ad53-b08e289c5dfc",
   "metadata": {},
   "source": [
    "Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0dca46-3dd9-41c7-9bd7-b81158862d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "import os\n",
    "\n",
    "credentials = Credentials(\n",
    "                   url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "                  )\n",
    "project_id = \"skills-network\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fbd22-8fa1-4aff-8afc-17144a4a8f13",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a228da0-790c-40e4-87d3-9b76ed6469c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, metadata, page_content):\n",
    "        self.metadata = metadata\n",
    "        self.page_content = page_content\n",
    "\n",
    "URLS_DICTIONARY = {\n",
    "    \"watsonx_wiki\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt\",\n",
    "    \"ibm_cloud_wiki\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt\",\n",
    "}\n",
    "COLLECTION_NAME = \"ibm_products\"\n",
    "\n",
    "documents = []\n",
    "\n",
    "for name, url in URLS_DICTIONARY.items():\n",
    "    print(f\"Loading from {url}\")\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = {\n",
    "            'metadata': {\"source\": url, \"name\": name},\n",
    "            'page_content': response.text\n",
    "        }\n",
    "\n",
    "        documents.append(Document(metadata=data['metadata'], page_content=data['page_content']))\n",
    "        print(f\"Loaded from {url}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve content from {url}\")\n",
    "\n",
    "\n",
    "print(documents[0].metadata)\n",
    "print(documents[0].page_content)\n",
    "\n",
    "# get rid of white space\n",
    "doc_id = 0\n",
    "for doc in documents:\n",
    "    doc.page_content = \" \".join(doc.page_content.split()) # remove white space\n",
    "\n",
    "    doc.metadata[\"id\"] = doc_id #make a document id and add it to the document metadata\n",
    "\n",
    "    print(doc.metadata)\n",
    "    doc_id += 1\n",
    "\n",
    "# Let's see how our sample document looks now after we cleaned it up.\n",
    "display(documents[1].metadata)\n",
    "display(documents[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95141b3b-6d09-4f0e-ab2f-13d993c1ee53",
   "metadata": {},
   "source": [
    "## Store\n",
    "\n",
    "Chunking: using `RecursiveCharacterTextSplitter` from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f209b-14a3-40e2-bb1b-5dfdfbed1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64865ae-8c2d-4f14-b025-e91b82b7a32d",
   "metadata": {},
   "source": [
    "Embedding with watsonx.ai\n",
    "\n",
    "Alternatively, we can use the [Hugging Face embeddings models](https://python.langchain.com/v0.2/docs/integrations/platforms/huggingface/#embedding-models) via LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d650c3f-b5ea-4d7a-9bd4-395a9ecd9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n",
    "    url=credentials[\"url\"],\n",
    "    project_id=project_id,\n",
    "    )\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4737e1a-d694-4c9a-8aed-74b7540149fe",
   "metadata": {},
   "source": [
    "Test it with `similarity_search_with_score`: returns the documents and the (Euclide) distance score (lower score is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a3f49-d451-49d5-93ee-bf91fca65fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is IBM?\"\n",
    "search = vectorstore.similarity_search_with_score(query, k=4)\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf20e0d-d198-4eaa-892f-5c0fdc2271ea",
   "metadata": {},
   "source": [
    "## Retrieve & Generate response\n",
    "\n",
    "* Setup a retriever\n",
    "* Generate response\n",
    "* Setup prompt template\n",
    "* Define helper function: format_docs\n",
    "* Setup a chain with context, prompt and llm model. Parse result with `StrOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09d19a-14b6-4089-8d01-6f38be70b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k':2})\n",
    "\n",
    "model_id = \"meta-llama/llama-3-405b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: 'greedy',\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 512,\n",
    "    GenParams.REPETITION_PENALTY:1,\n",
    "    GenParams.RETURN_OPTIONS: {'input_tokens': True,'generated_tokens': True, 'token_logprobs': True, 'token_ranks': True, }\n",
    "}\n",
    "\n",
    "# instantiate the LLM\n",
    "llm = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")\n",
    "\n",
    "template = \"\"\"Generate a summary of the context that answers the question. Explain the answer in multiple steps if possible. \n",
    "Answer style should match the context. Ideal Answer Length 2-3 sentences.\\n\\n{context}\\nQuestion: {question}\\nAnswer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ede2f3-6266-44ad-9d88-473b8e9e1103",
   "metadata": {},
   "source": [
    "Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c6e61-52e5-4421-8d3f-dcf322932c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chain.invoke(\"What is watsonx?\"), width=120) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c38f7-bcc2-4f72-a3c5-7a63efc68456",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "(\"Watsonx is an artificial intelligence platform developed by IBM, named after Thomas J. Watson, the company's founder \"\n",
    " 'and first CEO. It includes multiple services such as content generation, summarization, text classification, and '\n",
    " 'data extraction, and allows fine-tuning with its Tuning Studio. Additionally, Watsonx has a platform called '\n",
    " 'Watsonx.data, which helps clients address data-related issues and facilitates seamless data access.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
