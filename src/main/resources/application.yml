spring:
  application:
    name: chatty

  codec:
    log-request-details: true

  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 10MB

  webflux:
    multipart:
      max-in-memory-size: 10MB

  ai:
    chat:
      client:
        enabled: false # disable auto configuration of chat client

    retry:
      max-attempts: 5
      backoff:
        delay: 2000
        multiplier: 2

    model:
      #chat: openai # openai, bedrock-converse
      audio:
        transcription: fake # openai, fake
        speech: fake # openai, fake

    bedrock:
      aws:
        region: eu-central-1
        access-key: ${AWS_ACCESS_KEY_ID}
        secret-key: ${AWS_SECRET_ACCESS_KEY}
      converse:
        chat:
          options:
            model: eu.amazon.nova-lite-v1:0
            temperature: 0.8

    openai:
      #base-url: http://localhost:1234 # local llm
      base-url: https://api.openai.com # local llm
      api-key: ${OPENAI_API_KEY}
      audio:
        transcription:
          base-url: https://api.openai.com
          api-key: ${OPENAI_API_KEY}
          options:
            model: whisper-1
            response-format: json
        speech:
          base-url: https://api.openai.com
          api-key: ${OPENAI_API_KEY}
          options:
            model: tts-1
            voice: alloy
            response-format: mp3
            speed: 1.0
      http-client:
        connect-timeout: 60s
        read-timeout: 2m
